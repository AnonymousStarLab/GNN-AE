# GNN-based Anchor Embedding (GNN-AE)

The GNN-AE approach consists of both offline and online phases (i.e., offline.tar.gz and online.tar.gz).  GNN-AE is a graph neural network (GNN)-based anchor embedding approach, which allows exact subgraph matching.

As the data after offline training is large, we have prepared two examples (i.e., the yeast dataset and the syn-ws dataset) of the necessary data after offline training. You can run online processing directly without running offline operations first.

## Running Offline Process
Download the offline.tar.gz, and execute the following commands.

```
tar -xzvf offline.tar.gz
cd offline
python main.py
```

## Running Online Process
1. Download the online.tar.gz, execute the following commands.

```
tar -xzvf online.tar.gz
cd online
```

2. Under the root directory of the project, compile the source code.

```
mkdir build
cd build
cmake ..
make
```

3. Execute the following command to run the experiment over the Yeast dataset (the necessary pre-computed data produced by the offline process is already stored in the data directory).

```
./gnnae yeast
```

## Key Parameters
The key parameters of the offline process are in main.py

| name | description | 
| ----- | --------- |
| gnn_model_name | Optional GNN models, including 'GIN' and 'GAT' |
| emb_dimension | Dimension of the anchored embedding generated by GNN models |
| emb_precision | The precision for each dimension in anchored embeddings (default: 100) |
| dd_path_modes | Anchored path modes; '2' indicates hybrid anchored 1-radius paths, and '3' represents dual anchored 1-radius paths |

The key parameters of the online process are in the main.cpp

| name | description | 
| ----- | --------- |
| emb_precision | The precision for each dimension in anchored embeddings (default: 100) |
| parallel_threads | The number of parallel threads (default: 8) |
| path_index_type | Type of anchored path index mode; '2' indicates hybrid anchored 1-radius path indices, and '3' represents dual anchored 1-radius path indices |

## Experiment Datasets
You can run 'utils/generator.py' to generate random queries, and download the [real](https://github.com/RapidsAtHKUST/SubgraphMatching) datasets and the [synthetic](https://1drv.ms/f/c/0098e169ff45042e/IgCUX8TRKsETSLOVkcSah1qqARmB29GWDwWg4esUY2eaKkQ) datasets.  

